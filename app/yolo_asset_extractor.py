"""
yolo_asset_extractor.py - Extract figures and tables from document pages using DocLayout-YOLO.

This module:
1. Loads page images from docs_images/ (generated by prepare_images.py)
2. Runs DocLayout-YOLO to detect figures and tables
3. Crops detected regions and saves them as images
4. Generates metadata JSON files compatible with asset_processor.py

The output format matches what asset_processor.py expects, allowing seamless
integration into the existing pipeline without manual figure extraction.

Usage:
    python yolo_asset_extractor.py                    # Process all documents
    python yolo_asset_extractor.py --doc MyDocument   # Process specific document
    python yolo_asset_extractor.py --conf 0.5         # Custom confidence threshold
"""

import os
import json
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from collections import defaultdict

try:
    from doclayout_yolo import YOLOv10
    from PIL import Image
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("[Warning] doclayout-yolo not installed. Run: pip install doclayout-yolo")


# =============================================================================
# CONFIGURATION
# =============================================================================

# HuggingFace model for pre-trained weights
HUGGINGFACE_MODEL = "juliozhao/DocLayout-YOLO-DocStructBench"

# DocLayout-YOLO class mapping (from DocStructBench)
# We only care about figures and tables
YOLO_CLASSES = {
    0: "title",
    1: "plain_text",
    2: "abandon",
    3: "figure",
    4: "figure_caption",
    5: "table",
    6: "table_caption",
    7: "table_footnote",
    8: "isolate_formula",
    9: "formula_caption",
}

# Classes we want to extract as assets
ASSET_CLASSES = {"figure", "table"}


@dataclass
class DetectedAsset:
    """Represents a detected figure or table."""
    asset_type: str          # "figure" or "table"
    page_number: int         # 1-indexed page number
    bbox_pixels: Tuple[int, int, int, int]  # (x1, y1, x2, y2) in pixels
    confidence: float
    class_id: int
    doc_stem: str
    image_width: int
    image_height: int


def get_paths():
    """Calculate paths relative to this script file."""
    script_dir = Path(__file__).resolve().parent
    project_root = script_dir.parent if script_dir.name != "docs" else script_dir
    
    return {
        'images_dir': project_root / "docs_images",
        'exports_dir': project_root / "yolo_exports",  # Output directory for extracted assets
    }


def load_model(local_path: str = None) -> Optional['YOLOv10']:
    """Load DocLayout-YOLO model."""
    if not YOLO_AVAILABLE:
        return None
    
    if local_path and Path(local_path).exists():
        print(f"  Loading local model: {local_path}")
        return YOLOv10(local_path)
    else:
        print(f"  Loading pre-trained model from HuggingFace: {HUGGINGFACE_MODEL}")
        return YOLOv10.from_pretrained(HUGGINGFACE_MODEL)


def parse_image_filename(filename: str) -> Optional[Tuple[str, int]]:
    """
    Parse a page image filename to extract document stem and page number.
    
    Expected format: {doc_stem}_page{NNN}.jpg
    Example: "MyDocument_page001.jpg" -> ("MyDocument", 1)
    
    Returns:
        Tuple of (doc_stem, page_number) or None if parsing fails
    """
    import re
    
    # Match pattern: anything_pageNNN.jpg (or .jpeg, .png, etc.)
    match = re.match(r'^(.+)_page(\d+)\.[a-zA-Z]+$', filename)
    if match:
        doc_stem = match.group(1)
        page_num = int(match.group(2))
        return (doc_stem, page_num)
    return None


def group_images_by_document(images_dir: Path) -> Dict[str, List[Tuple[Path, int]]]:
    """
    Group page images by their document stem.
    
    Returns:
        Dict mapping doc_stem -> list of (image_path, page_number) tuples, sorted by page
    """
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    docs = defaultdict(list)
    
    if not images_dir.exists():
        print(f"[Error] Images directory not found: {images_dir}")
        return {}
    
    for img_path in images_dir.iterdir():
        if img_path.suffix.lower() not in image_extensions:
            continue
        
        parsed = parse_image_filename(img_path.name)
        if parsed:
            doc_stem, page_num = parsed
            docs[doc_stem].append((img_path, page_num))
    
    # Sort each document's pages by page number
    for doc_stem in docs:
        docs[doc_stem].sort(key=lambda x: x[1])
    
    return dict(docs)


def run_detection_on_image(
    model: 'YOLOv10',
    image_path: Path,
    doc_stem: str,
    page_number: int,
    confidence_threshold: float = 0.25,
    device: str = 'cpu'
) -> List[DetectedAsset]:
    """
    Run YOLO detection on a single page image.
    
    Returns:
        List of DetectedAsset objects for figures and tables found
    """
    assets = []
    
    # Run prediction
    results = model.predict(
        str(image_path),
        imgsz=1024,
        conf=confidence_threshold,
        save=False,
        device=device,
        verbose=False
    )
    
    if not results or len(results) == 0:
        return assets
    
    result = results[0]
    
    # Get image dimensions
    img_height, img_width = result.orig_shape
    
    # Process each detection
    for box in result.boxes:
        class_id = int(box.cls)
        class_name = YOLO_CLASSES.get(class_id, "unknown")
        
        # Only keep figures and tables
        if class_name not in ASSET_CLASSES:
            continue
        
        confidence = float(box.conf)
        x1, y1, x2, y2 = box.xyxy[0].tolist()
        
        # Normalize asset type for consistency with existing pipeline
        asset_type = "fig" if class_name == "figure" else "tab"
        
        asset = DetectedAsset(
            asset_type=asset_type,
            page_number=page_number,
            bbox_pixels=(int(x1), int(y1), int(x2), int(y2)),
            confidence=confidence,
            class_id=class_id,
            doc_stem=doc_stem,
            image_width=img_width,
            image_height=img_height
        )
        assets.append(asset)
    
    return assets


def crop_and_save_asset(
    source_image_path: Path,
    asset: DetectedAsset,
    output_dir: Path,
    asset_index: int,
    padding: int = 5
) -> Tuple[str, Path]:
    """
    Crop the detected region from the source image and save it.
    
    Args:
        source_image_path: Path to the full page image
        asset: The detected asset with bounding box
        output_dir: Directory to save cropped images
        asset_index: Index for unique naming
        padding: Pixels to add around the bounding box (to avoid cutting off edges)
    
    Returns:
        Tuple of (image_filename, full_path)
    """
    # Generate filename: {doc_stem}_{type}_{page}_{index}.jpg
    # Example: MyDocument_fig_p003_001.jpg
    filename = f"{asset.doc_stem}_{asset.asset_type}_p{asset.page_number:03d}_{asset_index:03d}.jpg"
    output_path = output_dir / filename
    
    # Open source image and crop
    with Image.open(source_image_path) as img:
        x1, y1, x2, y2 = asset.bbox_pixels
        
        # Add padding (but don't exceed image bounds)
        x1 = max(0, x1 - padding)
        y1 = max(0, y1 - padding)
        x2 = min(img.width, x2 + padding)
        y2 = min(img.height, y2 + padding)
        
        # Crop and save
        cropped = img.crop((x1, y1, x2, y2))
        cropped.save(output_path, "JPEG", quality=95)
    
    return filename, output_path


def create_asset_metadata(
    asset: DetectedAsset,
    image_filename: str,
    output_dpi: int = 200
) -> Dict:
    """
    Create metadata JSON for an asset in the format expected by asset_processor.py.
    
    This matches the structure of manually-exported assets so the downstream
    pipeline works without modification.
    """
    x1, y1, x2, y2 = asset.bbox_pixels
    width = x2 - x1
    height = y2 - y1
    
    # Generate a unique asset_id
    asset_id = f"{asset.doc_stem}_{asset.asset_type}_p{asset.page_number}_{x1}_{y1}"
    
    metadata = {
        "asset_id": asset_id,
        "asset_type": asset.asset_type,  # "fig" or "tab"
        "page": asset.page_number,
        "bbox": {
            "pixels": [x1, y1, width, height],  # [x, y, width, height] format
            "page_width_px": asset.image_width,
            "page_height_px": asset.image_height,
        },
        "export": {
            "image_file": image_filename,
            "dpi": output_dpi,
            "format": "JPEG",
        },
        "detection": {
            "method": "DocLayout-YOLO",
            "model": HUGGINGFACE_MODEL,
            "confidence": round(asset.confidence, 4),
            "class_id": asset.class_id,
            "class_name": YOLO_CLASSES.get(asset.class_id, "unknown"),
        }
    }
    
    return metadata


def process_document(
    model: 'YOLOv10',
    doc_stem: str,
    page_images: List[Tuple[Path, int]],
    output_dir: Path,
    confidence_threshold: float = 0.25,
    device: str = 'cpu'
) -> List[Dict]:
    """
    Process all pages of a document and extract assets.
    
    Returns:
        List of metadata dictionaries for all detected assets
    """
    # Create document-specific output directory
    doc_output_dir = output_dir / doc_stem
    doc_output_dir.mkdir(parents=True, exist_ok=True)
    
    all_assets_metadata = []
    asset_counters = {"fig": 0, "tab": 0}
    
    print(f"  Processing {len(page_images)} pages...")
    
    for image_path, page_number in page_images:
        # Run detection
        detected_assets = run_detection_on_image(
            model=model,
            image_path=image_path,
            doc_stem=doc_stem,
            page_number=page_number,
            confidence_threshold=confidence_threshold,
            device=device
        )
        
        if detected_assets:
            print(f"    Page {page_number}: Found {len(detected_assets)} assets")
        
        # Process each detected asset
        for asset in detected_assets:
            asset_counters[asset.asset_type] += 1
            asset_index = asset_counters[asset.asset_type]
            
            # Crop and save the image
            image_filename, _ = crop_and_save_asset(
                source_image_path=image_path,
                asset=asset,
                output_dir=doc_output_dir,
                asset_index=asset_index
            )
            
            # Create metadata
            metadata = create_asset_metadata(asset, image_filename)
            all_assets_metadata.append(metadata)
            
            # Save individual metadata JSON (for compatibility with asset_processor)
            json_filename = image_filename.replace('.jpg', '.json')
            json_path = doc_output_dir / json_filename
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2)
    
    return all_assets_metadata


def run_yolo_extraction(
    images_dir: Optional[Path] = None,
    output_dir: Optional[Path] = None,
    doc_filter: Optional[str] = None,
    confidence_threshold: float = 0.25,
    device: str = 'cpu',
    model_path: Optional[str] = None
) -> Dict[str, List[Dict]]:
    """
    Main function to run YOLO extraction on all documents (or a specific one).
    
    Args:
        images_dir: Directory containing page images (defaults to docs_images/)
        output_dir: Directory for output (defaults to yolo_exports/)
        doc_filter: If provided, only process this document stem
        confidence_threshold: Minimum confidence for detections
        device: 'cpu', 'cuda:0', or 'mps' for Apple Silicon
        model_path: Optional path to local model weights
    
    Returns:
        Dict mapping doc_stem -> list of asset metadata
    """
    if not YOLO_AVAILABLE:
        print("[Error] doclayout-yolo not installed. Run: pip install doclayout-yolo")
        return {}
    
    # Get default paths if not provided
    paths = get_paths()
    images_dir = Path(images_dir) if images_dir else paths['images_dir']
    output_dir = Path(output_dir) if output_dir else paths['exports_dir']
    
    print("=" * 60)
    print("YOLO ASSET EXTRACTION")
    print("=" * 60)
    print(f"  Images directory: {images_dir}")
    print(f"  Output directory: {output_dir}")
    print(f"  Confidence threshold: {confidence_threshold}")
    print(f"  Device: {device}")
    print()
    
    # Group images by document
    docs = group_images_by_document(images_dir)
    
    if not docs:
        print("[Error] No page images found!")
        return {}
    
    # Filter to specific document if requested
    if doc_filter:
        if doc_filter in docs:
            docs = {doc_filter: docs[doc_filter]}
        else:
            print(f"[Error] Document '{doc_filter}' not found in images directory.")
            print(f"  Available documents: {list(docs.keys())}")
            return {}
    
    print(f"  Found {len(docs)} document(s) to process")
    print()
    
    # Load model once
    print("Loading YOLO model...")
    model = load_model(model_path)
    if model is None:
        return {}
    print()
    
    # Process each document
    output_dir.mkdir(parents=True, exist_ok=True)
    results = {}
    
    for doc_stem, page_images in docs.items():
        print(f"[{doc_stem}]")
        
        assets = process_document(
            model=model,
            doc_stem=doc_stem,
            page_images=page_images,
            output_dir=output_dir,
            confidence_threshold=confidence_threshold,
            device=device
        )
        
        results[doc_stem] = assets
        
        # Summary for this document
        fig_count = sum(1 for a in assets if a['asset_type'] == 'fig')
        tab_count = sum(1 for a in assets if a['asset_type'] == 'tab')
        print(f"  Extracted: {fig_count} figures, {tab_count} tables")
        print()
    
    # Overall summary
    print("=" * 60)
    print("EXTRACTION COMPLETE")
    print("=" * 60)
    total_figs = sum(sum(1 for a in assets if a['asset_type'] == 'fig') for assets in results.values())
    total_tabs = sum(sum(1 for a in assets if a['asset_type'] == 'tab') for assets in results.values())
    print(f"  Total figures: {total_figs}")
    print(f"  Total tables: {total_tabs}")
    print(f"  Output: {output_dir}")
    
    return results


# =============================================================================
# PIPELINE INTEGRATION HELPER
# =============================================================================

def get_yolo_exports_dir() -> Path:
    """
    Get the YOLO exports directory path.
    
    This is used by simple_pipeline.py to point asset_processor.py
    at the YOLO-generated assets instead of manual exports.
    """
    return get_paths()['exports_dir']


# =============================================================================
# CLI
# =============================================================================

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Extract figures and tables from document pages using DocLayout-YOLO"
    )
    parser.add_argument(
        '--images-dir', '-i',
        type=str,
        default=None,
        help="Directory containing page images (default: docs_images/)"
    )
    parser.add_argument(
        '--output-dir', '-o',
        type=str,
        default=None,
        help="Output directory for extracted assets (default: yolo_exports/)"
    )
    parser.add_argument(
        '--doc', '-d',
        type=str,
        default=None,
        help="Process only this document stem"
    )
    parser.add_argument(
        '--conf', '-c',
        type=float,
        default=0.25,
        help="Confidence threshold for detections (default: 0.25)"
    )
    parser.add_argument(
        '--device',
        type=str,
        default='cpu',
        help="Device: 'cpu', 'cuda:0', or 'mps' (default: cpu)"
    )
    parser.add_argument(
        '--model',
        type=str,
        default=None,
        help="Path to local model weights (optional)"
    )
    
    args = parser.parse_args()
    
    run_yolo_extraction(
        images_dir=Path(args.images_dir) if args.images_dir else None,
        output_dir=Path(args.output_dir) if args.output_dir else None,
        doc_filter=args.doc,
        confidence_threshold=args.conf,
        device=args.device,
        model_path=args.model
    )